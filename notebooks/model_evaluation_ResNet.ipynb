{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torchvision.models import ResNet50_Weights\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...\"\n",
    "            )\n",
    "        torch.save(model.state_dict(), path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts: Counter({0: 62920, 1: 44509})\n",
      "Validation class counts: Counter({0: 13482, 1: 9537})\n",
      "Limited Train class counts: Counter({0: 22254, 1: 22254})\n",
      "Limited Validation class counts: Counter({0: 4768, 1: 4768})\n"
     ]
    }
   ],
   "source": [
    "train_dataset_full = ImageFolder(root=\"../data/processed/train\", transform=transform)\n",
    "val_dataset_full = ImageFolder(root=\"../data/processed/val\", transform=transform)\n",
    "\n",
    "\n",
    "def count_images_per_class(dataset):\n",
    "    class_counts = Counter()\n",
    "    for _, label in dataset.samples:\n",
    "        class_counts[label] += 1\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "train_class_counts = count_images_per_class(train_dataset_full)\n",
    "val_class_counts = count_images_per_class(val_dataset_full)\n",
    "\n",
    "print(f\"Train class counts: {train_class_counts}\")\n",
    "print(f\"Validation class counts: {val_class_counts}\")\n",
    "\n",
    "\n",
    "def balance_dataset(dataset, limit=0.1):\n",
    "    class_indices = {\n",
    "        cls: np.where(np.array(dataset.targets) == cls)[0]\n",
    "        for cls in range(len(dataset.classes))\n",
    "    }\n",
    "    min_class_count = int(\n",
    "        min(len(indices) for indices in class_indices.values()) * limit\n",
    "    )\n",
    "\n",
    "    balanced_indices = []\n",
    "    for indices in class_indices.values():\n",
    "        balanced_indices.extend(\n",
    "            np.random.choice(indices, min_class_count, replace=False)\n",
    "        )\n",
    "\n",
    "    return Subset(dataset, balanced_indices)\n",
    "\n",
    "\n",
    "def limit_dataset(dataset, limit):\n",
    "    indices = np.random.choice(len(dataset), int(len(dataset) * limit), replace=False)\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "\n",
    "train_dataset = balance_dataset(train_dataset_full, limit=0.5)\n",
    "val_dataset = balance_dataset(val_dataset_full, limit=0.5)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "def count_images_per_class_subset(subset):\n",
    "    class_counts = Counter()\n",
    "    for idx in subset.indices:\n",
    "        _, label = subset.dataset.samples[idx]\n",
    "        class_counts[label] += 1\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "limited_train_class_counts = count_images_per_class_subset(train_dataset)\n",
    "limited_val_class_counts = count_images_per_class_subset(val_dataset)\n",
    "\n",
    "print(f\"Limited Train class counts: {limited_train_class_counts}\")\n",
    "print(f\"Limited Validation class counts: {limited_val_class_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of the device, loss criterion and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the GPU!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "\n",
    "resnet50 = resnet50.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet50.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints/ResNet/\"\n",
    "saved_model_dir = \"saved_models/ResNet/\"\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pth\")\n",
    "saved_model_path = os.path.join(saved_model_dir, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=25,\n",
    "    patience=5,\n",
    "    checkpoint_path=\"checkpoint.pth\",\n",
    "):\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[\"train\"]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[\"train\"].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[\"train\"].dataset)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\"\n",
    "        )\n",
    "        history[\"train_loss\"].append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloaders[\"val\"]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_epoch_loss = val_running_loss / len(dataloaders[\"val\"].dataset)\n",
    "        val_epoch_acc = val_running_corrects.double() / len(dataloaders[\"val\"].dataset)\n",
    "\n",
    "        print(\n",
    "            f\"Validation Loss: {val_epoch_loss:.4f}, Validation Acc: {val_epoch_acc:.4f}\"\n",
    "        )\n",
    "        history[\"val_loss\"].append(val_epoch_loss)\n",
    "        history[\"val_acc\"].append(val_epoch_acc)\n",
    "\n",
    "       \n",
    "        early_stopping(val_epoch_loss, model, checkpoint_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    return model, history\n",
    "\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_model(\n",
    "    resnet50,\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=10,\n",
    "    patience=5,\n",
    "    checkpoint_path=checkpoint_path,\n",
    ")\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_history(history_path):\n",
    "    import json\n",
    "\n",
    "    with open(history_path, \"r\") as f:\n",
    "        history = json.load(f)\n",
    "    return history\n",
    "\n",
    "\n",
    "def save_history(history, history_path):\n",
    "   \n",
    "\n",
    "    with open(history_path, \"w\") as f:\n",
    "        json.dump(history, f)\n",
    "\n",
    "\n",
    "save_history(history, \"training_history.json\")\n",
    "\n",
    "history = load_history(\"training_history.json\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"val_acc\"], label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
