{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...\"\n",
    "            )\n",
    "        torch.save(model.state_dict(), path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sit3kk/Bird_Detector/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sit3kk/Bird_Detector/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/sit3kk/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:02<00:00, 34.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset_full = ImageFolder(root=\"../data/processed/train\", transform=transform)\n",
    "val_dataset_full = ImageFolder(root=\"../data/processed/val\", transform=transform)\n",
    "\n",
    "\n",
    "def limit_dataset(dataset, limit=0.1):\n",
    "    indices = np.random.choice(len(dataset), int(len(dataset) * limit), replace=False)\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "\n",
    "train_dataset = limit_dataset(train_dataset_full, limit=0.1)\n",
    "val_dataset = limit_dataset(val_dataset_full, limit=0.1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of the device, loss criterion and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50 = resnet50.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet50.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints/ResNet/\"\n",
    "saved_model_dir = \"saved_models/ResNet/\"\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pth\")\n",
    "saved_model_path = os.path.join(saved_model_dir, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=25,\n",
    "    patience=5,\n",
    "    checkpoint_path=\"checkpoint.pth\",\n",
    "):\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[\"train\"]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[\"train\"].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[\"train\"].dataset)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\"\n",
    "        )\n",
    "        history[\"train_loss\"].append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloaders[\"val\"]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_epoch_loss = val_running_loss / len(dataloaders[\"val\"].dataset)\n",
    "        val_epoch_acc = val_running_corrects.double() / len(dataloaders[\"val\"].dataset)\n",
    "\n",
    "        print(\n",
    "            f\"Validation Loss: {val_epoch_loss:.4f}, Validation Acc: {val_epoch_acc:.4f}\"\n",
    "        )\n",
    "        history[\"val_loss\"].append(val_epoch_loss)\n",
    "        history[\"val_acc\"].append(val_epoch_acc)\n",
    "\n",
    "       \n",
    "        early_stopping(val_epoch_loss, model, checkpoint_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    return model, history\n",
    "\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_model(\n",
    "    resnet50,\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=10,\n",
    "    patience=5,\n",
    "    checkpoint_path=checkpoint_path,\n",
    ")\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_history(history_path):\n",
    "    import json\n",
    "\n",
    "    with open(history_path, \"r\") as f:\n",
    "        history = json.load(f)\n",
    "    return history\n",
    "\n",
    "\n",
    "def save_history(history, history_path):\n",
    "   \n",
    "\n",
    "    with open(history_path, \"w\") as f:\n",
    "        json.dump(history, f)\n",
    "\n",
    "\n",
    "save_history(history, \"training_history.json\")\n",
    "\n",
    "history = load_history(\"training_history.json\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"val_acc\"], label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
