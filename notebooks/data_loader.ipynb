# %% [markdown]
# ## Importing Libraries and Setting Up Paths

# %%
import os
import shutil
import random
from PIL import Image
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# %% [markdown]
# ## Paths to Directories

# %%
raw_data_dir = "../data/raw"
processed_data_dir = "../data/processed"

# %%
if not os.path.exists(processed_data_dir):
    os.makedirs(processed_data_dir)

train_dir = os.path.join(processed_data_dir, "train")
test_dir = os.path.join(processed_data_dir, "test")

if not os.path.exists(train_dir):
    os.makedirs(train_dir)

if not os.path.exists(test_dir):
    os.makedirs(test_dir)

# %% [markdown]
# ## Copying and Shuffling Files

# %%
sub_dirs = ["bird", "nonbird"]


def copy_and_shuffle_files(src_dir, dest_dir, split_ratio=0.8):
    for sub_dir in sub_dirs:
        full_sub_dir = os.path.join(src_dir, sub_dir)
        files = [
            os.path.join(full_sub_dir, f)
            for f in os.listdir(full_sub_dir)
            if os.path.isfile(os.path.join(full_sub_dir, f))
        ]
        random.shuffle(files)

        split_index = int(len(files) * split_ratio)
        train_files = files[:split_index]
        test_files = files[split_index:]

        for phase, file_set in zip(["train", "test"], [train_files, test_files]):
            dest_sub_dir = os.path.join(dest_dir, phase, sub_dir)
            if not os.path.exists(dest_sub_dir):
                os.makedirs(dest_sub_dir)
            for file in file_set:
                shutil.copy(file, dest_sub_dir)


copy_and_shuffle_files(raw_data_dir, processed_data_dir)

# %% [markdown]
# ## Rescaling Images

# %%
rescaled_size = (224, 224)


def rescale_images_in_dir(src_dir, size):
    for root, dirs, files in os.walk(src_dir):
        for file_name in files:
            file_path = os.path.join(root, file_name)
            if os.path.isfile(file_path):
                with Image.open(file_path) as img:
                    img_rescaled = img.resize(size)
                    img_rescaled.save(file_path)


rescale_images_in_dir(processed_data_dir, rescaled_size)

# %% [markdown]
# ## Setting Up DataLoader

# %%
# Define transformations to apply to the images
transform = transforms.Compose(
    [
        transforms.ToTensor(),  # Convert images to tensors
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
        ),  # Normalize images
    ]
)

# Load the datasets using ImageFolder
train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)
test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)

# Create DataLoaders for each dataset
batch_size = 32

train_loader = DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4
)
test_loader = DataLoader(
    test_dataset, batch_size=batch_size, shuffle=False, num_workers=4
)

# %% [markdown]
# ## Checking DataLoader Sizes and Displaying a Batch

# %%
# Check the size of each DataLoader
print(f"Train dataset size: {len(train_loader.dataset)}")
print(f"Test dataset size: {len(test_loader.dataset)}")

# Example iteration over the DataLoader
for images, labels in train_loader:
    print(f"Batch of images shape: {images.shape}")
    print(f"Batch of labels shape: {labels.shape}")
    break
