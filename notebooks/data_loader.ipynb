{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Setting Up Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 16:54:09.903873: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 16:54:11.181438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 8\n",
      "Available memory: 10800119808 bytes\n",
      "2.3.0+cu121\n",
      "0.18.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import psutil\n",
    "import tensorflow as tf\n",
    "\n",
    "cpus = psutil.cpu_count()\n",
    "print(f\"Available CPUs: {cpus}\")\n",
    "print(f\"Available memory: {psutil.virtual_memory().available} bytes\")\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths to Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = \"../data/raw\"\n",
    "processed_data_dir = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(processed_data_dir):\n",
    "    os.makedirs(processed_data_dir)\n",
    "\n",
    "train_dir = os.path.join(processed_data_dir, \"train\")\n",
    "test_dir = os.path.join(processed_data_dir, \"test\")\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying and Shuffling Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dirs = [\"bird\", \"nonbird\"]\n",
    "\n",
    "\n",
    "def copy_and_shuffle_files(src_dir, dest_dir, train_ratio=0.7, val_ratio=0.15):\n",
    "    \"\"\"Copy files into training, validation, and testing directories with specified ratios.\"\"\"\n",
    "    for sub_dir in sub_dirs:\n",
    "        full_sub_dir = os.path.join(src_dir, sub_dir)\n",
    "        files = [\n",
    "            os.path.join(full_sub_dir, f)\n",
    "            for f in os.listdir(full_sub_dir)\n",
    "            if os.path.isfile(os.path.join(full_sub_dir, f))\n",
    "        ]\n",
    "        random.shuffle(files)\n",
    "\n",
    "        n_train = int(len(files) * train_ratio)\n",
    "        n_val = int(len(files) * val_ratio)\n",
    "\n",
    "        train_files = files[:n_train]\n",
    "        val_files = files[n_train : n_train + n_val]\n",
    "        test_files = files[n_train + n_val :]\n",
    "\n",
    "        for phase, file_set in zip(\n",
    "            [\"train\", \"val\", \"test\"], [train_files, val_files, test_files]\n",
    "        ):\n",
    "            dest_sub_dir = os.path.join(dest_dir, phase, sub_dir)\n",
    "            if not os.path.exists(dest_sub_dir):\n",
    "                os.makedirs(dest_sub_dir)\n",
    "            for file in file_set:\n",
    "                shutil.copy(file, dest_sub_dir)\n",
    "\n",
    "\n",
    "copy_and_shuffle_files(raw_data_dir, processed_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_images_in_dir(src_dir, size):\n",
    "    \"\"\"Rescale images in directory to given size.\"\"\"\n",
    "    for root, dirs, files in os.walk(src_dir):\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                with Image.open(file_path) as img:\n",
    "                    img_rescaled = img.resize(size)\n",
    "                    img_rescaled.save(file_path)\n",
    "\n",
    "\n",
    "rescaled_size = (224, 224)\n",
    "rescale_images_in_dir(processed_data_dir, rescaled_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
