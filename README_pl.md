[EN](README.md) | [PL](README_pl.md)

# ğŸ¦ Projekt: Wykrywanie PtakÃ³w na ZdjÄ™ciach

Celem projektu byÅ‚o stworzenie modelu, ktÃ³ry bÄ™dzie sprawdzaÅ‚, czy na zdjÄ™ciu wystÄ™puje ptak, czy nie. RozwiÄ…zanie zostaÅ‚o zastosowane w projekcie [Bird Species Recognition](https://github.com/bubiasz/team-project).

## ğŸ“Š 1. Data Set

Wykorzystany zbiÃ³r danych to mix CIFAR-10, COCO, Birdsnap i CUB-200-2011, co daÅ‚o nam zbiÃ³r zawierajÄ…cy okoÅ‚o 150 tysiÄ™cy zdjÄ™Ä‡ w dwÃ³ch kategoriach: ptak i nie-ptak.

NajwiÄ™kszym problemem w wyszukaniu odpowiedniego zbioru byÅ‚o znalezienie odpowiednich datasetÃ³w, ktÃ³re bÄ™dÄ… jednoczeÅ›nie rÃ³Å¼norodne i nie bÄ™dÄ… zawieraÅ‚y ptakÃ³w. WybÃ³r padÅ‚ na CIFAR-10 i COCO, poniewaÅ¼ sÄ… to bardzo duÅ¼e zbiory podzielone na kategorie.

## ğŸš€ 2. Data Loader

W celu przyspieszenia treningu modeli zostaÅ‚ stworzony data loader, ktÃ³ry ma za zadanie rozdzieliÄ‡ oraz przetasowaÄ‡ zdjÄ™cia do folderÃ³w `train`, `val` oraz `test`. Po wykonaniu tej operacji nastÄ™puje rescaling zdjÄ™Ä‡ do odpowiednich wymiarÃ³w.

## ğŸ§  3. Model

### MobileNetV2 (CNN, Convolutional Neural Network)

Zaprojektowany z myÅ›lÄ… o urzÄ…dzeniach mobilnych.

**Plusy:**
- WydajnoÅ›Ä‡ obliczeniowa
- EfektywnoÅ›Ä‡ pamiÄ™ciowa
- WszechstronnoÅ›Ä‡
- SkalowalnoÅ›Ä‡

**Minusy:**
- Mniejsza dokÅ‚adnoÅ›Ä‡ niÅ¼ duÅ¼e modele
- TrudnoÅ›ci z dostrojeniem

#### Proces przygotowania:

```python
def build_model(num_classes):
    # Åadowanie wstÄ™pnie wytrenowanego modelu MobileNetV2 bez gÃ³rnych warstw (bez warstw klasyfikacyjnych)
    base_model = MobileNetV2(
        input_shape=(224, 224, 3),  # Definiowanie ksztaÅ‚tu wejÅ›ciowego obrazÃ³w (224x224x3)
        include_top=False,          # PominiÄ™cie gÃ³rnej warstwy klasyfikacyjnej modelu
        weights="imagenet"          # UÅ¼ycie wag wstÄ™pnie wytrenowanych na zbiorze danych ImageNet
    )

    # Dodanie wÅ‚asnych warstw na szczycie modelu
    x = base_model.output  # WyjÅ›cie z wstÄ™pnie wytrenowanego modelu
    x = GlobalAveragePooling2D()(x)  # Dodanie globalnej warstwy Å›redniego Å‚Ä…czenia w celu zmniejszenia wymiarowoÅ›ci danych
    x = Dense(128, activation="relu")(x)  # Dodanie gÄ™stej warstwy z 128 neuronami i funkcjÄ… aktywacji ReLU
    predictions = Dense(num_classes, activation="softmax")(x)  # Dodanie warstwy wyjÅ›ciowej z funkcjÄ… aktywacji softmax (num_classes to liczba klas)

    # Stworzenie finalnego modelu z oryginalnym wejÅ›ciem i nowym wyjÅ›ciem
    model = Model(inputs=base_model.input, outputs=predictions)
    return model

# Definiowanie liczby klas (w tym przypadku 2: ptak i nie-ptak)
num_classes = 2 

# Budowanie modelu
model = build_model(num_classes)

# WyÅ›wietlenie podsumowania modelu, aby zobaczyÄ‡ jego architekturÄ™
model.summary()
```

Podczas trenowania batch_size zostaÅ‚ ustawiony na 32 ze wzglÄ™du na maÅ‚Ä… moc obliczeniowÄ… (przy wyÅ¼szych wartoÅ›ciach program siÄ™ crashowaÅ‚).

### ğŸ§© Rezultat

W modelu od okoÅ‚o 6 epoki zaczÄ™Å‚a spadaÄ‡ skutecznoÅ›Ä‡ na zbiorze walidacyjnym. Ostatecznie po caÅ‚ym treningu wybrano najkorzystniejszÄ… wersjÄ™, ktÃ³ra uzyskaÅ‚a skutecznoÅ›Ä‡ na zbiorze testowym na poziomie 74%, co byÅ‚o niesatysfakcjonujÄ…cym wynikiem.

**BÅ‚Ä™dy w tej iteracji:**
- Zbyt maÅ‚y zbiÃ³r - wykorzystano 10% caÅ‚ego zbioru w celu zaoszczÄ™dzenia czasu na szkolenie.
- Trenowanie na CPU - brak zainstalowanych CUDA i cuDNN powodowaÅ‚ trenowanie modelu na procesorze, co znacznie wydÅ‚uÅ¼yÅ‚o czas treningu.
- Brak regularyzacji - spadek efektywnoÅ›ci mÃ³gÅ‚ byÄ‡ spowodowany overfittingiem.
- NierÃ³wnowaÅ¼one dane - zdjÄ™Ä‡ ptakÃ³w byÅ‚o kilkadziesiÄ…t procent wiÄ™cej, co mogÅ‚o spowodowaÄ‡, Å¼e model preferowaÅ‚ tÄ™ klasÄ™ bardziej.

## ğŸ”„ Zmiana PodejÅ›cia

Po uzyskaniu wynikÃ³w duÅ¼o poniÅ¼ej oczekiwaÅ„, postanowiliÅ›my zmieniÄ‡ podejÅ›cie.

### ResNet (Residual Neural Network) 
Rodzina gÅ‚Ä™bokich sieci neuronowych

**Plusy:**
- Wysoka dokÅ‚adnoÅ›Ä‡
- Efektywne trenowanie
- Åatwiejsze dostosowanie

**Minusy:**
- ZÅ‚oÅ¼onoÅ›Ä‡ obliczeniowa
- WiÄ™ksze ryzyko przeuczenia
- ZÅ‚oÅ¼onoÅ›Ä‡ architektury

WybraliÅ›my pretrenowany model ResNet50 (wariant skÅ‚adajÄ…cy siÄ™ z 50 warstw) jako kompromis pomiÄ™dzy zÅ‚oÅ¼onoÅ›ciÄ… a efektywnoÅ›ciÄ….

**Poprawione bÅ‚Ä™dy w stosunku do poprzedniego rozwiÄ…zania:**
- Trenowanie modelu na GPU w celu przyspieszenia procesu.
- ZwiÄ™kszenie licznoÅ›ci zbioru do okoÅ‚o 50%.
- Zbalansowanie licznoÅ›ci klas miÄ™dzy bird a nonbird.

### ğŸ’¡ Opis RozwiÄ…zania

Klasa EarlyStopping sÅ‚uÅ¼y do monitorowania procesu trenowania modelu i automatycznego zatrzymania treningu, jeÅ›li wskaÅºnik przestaje siÄ™ poprawiaÄ‡. JeÅ›li strata walidacyjna siÄ™ poprawia, model jest zapisywany, a najlepszy wynik i minimalna strata walidacyjna sÄ… aktualizowane. Po przejÅ›ciu wszystkich 10 epok ostateczny model jest zapisywany w `saved_models`.

```python
class EarlyStopping:
    def __init__(self, patience=5, verbose=False, delta=0):
        self.patience = patience          # Liczba epok bez poprawy, po ktÃ³rej trening zostanie zatrzymany
        self.verbose = verbose            # Flaga okreÅ›lajÄ…ca, czy drukowaÄ‡ komunikaty
        self.counter = 0                  # Licznik epok bez poprawy
        self.best_score = None            # Najlepszy wynik (najniÅ¼sza strata walidacyjna)
        self.early_stop = False           # Flaga okreÅ›lajÄ…ca, czy zatrzymaÄ‡ trening
        self.val_loss_min = np.Inf        # Minimalna strata walidacyjna (inicjalizowana jako nieskoÅ„czonoÅ›Ä‡)
        self.delta = delta                # Minimalna rÃ³Å¼nica wymagana do uznania poprawy

    def __call__(self, val_loss, model, path):
        score = -val_loss                 # Negatywna wartoÅ›Ä‡ straty walidacyjnej, aby minimalizacja byÅ‚a optymalizacjÄ… maksymalizacji

        if self.best_score is None:       # Pierwsze wywoÅ‚anie
            self.best_score = score       # Ustawienie poczÄ…tkowego najlepszego wyniku
            self.save_checkpoint(val_loss, model, path)  # Zapis modelu
        elif score < self.best_score + self.delta:  # Brak poprawy
            self.counter += 1             # ZwiÄ™kszenie licznika epok bez poprawy
            if self.verbose:
                print(f"EarlyStopping counter: {self.counter} out of {self.patience}")
            if self.counter >= self.patience:  # JeÅ›li licznik przekroczy wartoÅ›Ä‡ patience
                self.early_stop = True    # Ustawienie flagi wczesnego zatrzymania
        else:                             # Poprawa wyniku
            self.best_score = score       # Aktualizacja najlepszego wyniku
            self.save_checkpoint(val_loss, model, path)  # Zapis modelu
            self.counter = 0              # Resetowanie licznika

    def save_checkpoint(self, val_loss, model, path):
        if self.verbose:
            print(
                f"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ..."
            )
        torch.save(model.state_dict(), path)  # Zapis stanu modelu do pliku
        self.val_loss_min = val_loss          # Aktualizacja minimalnej straty walidacyjnej
```

### ğŸ”§ Przygotowanie Modelu ResNet50

```python 
# ZaÅ‚adowanie wstÄ™pnie wytrenowanego modelu ResNet50
resnet50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)

# ZamroÅ¼enie wszystkich parametrÃ³w w modelu
for param in resnet50.parameters():
    param.requires_grad = False

# Modyfikacja ostatniej warstwy, aby dopasowaÄ‡ jÄ… do liczby klas
num_features = resnet50.fc.in_features
resnet50.fc = nn.Linear(num_features, 2)

```
## â„ï¸ ZamroÅ¼enie Wag
ZamroÅ¼enie wag wstÄ™pnie wytrenowanego modelu pozwala na zatrzymanie procesu aktualizacji tych wag podczas treningu, co zmniejsza ryzyko przeuczenia (overfitting) i przyspiesza trening. Skupiamy siÄ™ jedynie na trenowaniu nowych lub zmodyfikowanych warstw modelu.

Oryginalna warstwa koÅ„cowa ResNet50 jest przystosowana do klasyfikacji na 1000 klas ImageNet. W naszym zadaniu mamy tylko dwie klasy (ptak i nie-ptak), dlatego musielismy dostosowaÄ‡ ostatniÄ… warstwÄ™ do tej liczby klas. ZastÄ™pujÄ…c jÄ… nowÄ… warstwÄ… z dwoma neuronami, model moÅ¼e generowaÄ‡ odpowiednie predykcje dla naszego specyficznego zadania.


## ğŸ‹ï¸â€â™‚ï¸ Trening Modeluâ€
```python 
def train_model(
    model,                     # Model, ktÃ³ry bÄ™dzie trenowany
    dataloaders,               # ZbiÃ³r danych treningowych i walidacyjnych w postaci sÅ‚ownika
    criterion,                 # Funkcja straty (loss function)
    optimizer,                 # Optymalizator do aktualizacji wag modelu
    num_epochs=25,             # Liczba epok treningowych (domyÅ›lnie 25)
    patience=5,                # Liczba epok bez poprawy przed zatrzymaniem (early stopping)
    checkpoint_path="checkpoint.pth",  # ÅšcieÅ¼ka do zapisu najlepszego modelu
):
    early_stopping = EarlyStopping(patience=patience, verbose=True)  # Inicjalizacja wczesnego zatrzymywania
    history = {"train_loss": [], "val_loss": [], "val_acc": []}       # Historia treningu

    print("Starting training...")  # RozpoczÄ™cie treningu

    for epoch in range(num_epochs):  # PÄ™tla przez wszystkie epoki
        model.train()  # Ustawienie modelu w tryb treningowy
        running_loss = 0.0  # Inicjalizacja straty dla bieÅ¼Ä…cej epoki
        running_corrects = 0  # Inicjalizacja liczby poprawnych predykcji dla bieÅ¼Ä…cej epoki

        print(f"Epoch {epoch+1}/{num_epochs}")  # Informacja o bieÅ¼Ä…cej epoce

        for inputs, labels in dataloaders["train"]:  # PÄ™tla przez wszystkie batch'e danych treningowych
            inputs = inputs.to(device)  # Przeniesienie danych wejÅ›ciowych na urzÄ…dzenie (CPU/GPU)
            labels = labels.to(device)  # Przeniesienie etykiet na urzÄ…dzenie (CPU/GPU)

            optimizer.zero_grad()  # Wyzerowanie gradientÃ³w
            outputs = model(inputs)  # Przepuszczenie danych przez model (forward pass)
            loss = criterion(outputs, labels)  # Obliczenie straty
            loss.backward()  # Obliczenie gradientÃ³w (backward pass)
            optimizer.step()  # Aktualizacja wag modelu

            _, preds = torch.max(outputs, 1)  # Uzyskanie predykcji
            running_loss += loss.item() * inputs.size(0)  # Aktualizacja skumulowanej straty
            running_corrects += torch.sum(preds == labels.data)  # Aktualizacja liczby poprawnych predykcji

        epoch_loss = running_loss / len(dataloaders["train"].dataset)  # Obliczenie Å›redniej straty dla epoki
        epoch_acc = running_corrects.double() / len(dataloaders["train"].dataset)  # Obliczenie dokÅ‚adnoÅ›ci dla epoki

        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}")  # Informacja o wynikach epoki
        history["train_loss"].append(epoch_loss)  # Zapis straty treningowej do historii

        model.eval()  # Ustawienie modelu w tryb ewaluacji
        val_running_loss = 0.0  # Inicjalizacja straty walidacyjnej
        val_running_corrects = 0  # Inicjalizacja liczby poprawnych predykcji walidacyjnych

        with torch.no_grad():  # WyÅ‚Ä…czenie obliczania gradientÃ³w podczas walidacji
            for inputs, labels in dataloaders["val"]:  # PÄ™tla przez wszystkie batch'e danych walidacyjnych
                inputs = inputs.to(device)  # Przeniesienie danych wejÅ›ciowych na urzÄ…dzenie (CPU/GPU)
                labels = labels.to(device)  # Przeniesienie etykiet na urzÄ…dzenie (CPU/GPU)

                outputs = model(inputs)  # Przepuszczenie danych przez model (forward pass)
                loss = criterion(outputs, labels)  # Obliczenie straty

                _, preds = torch.max(outputs, 1)  # Uzyskanie predykcji
                val_running_loss += loss.item() * inputs.size(0)  # Aktualizacja skumulowanej straty walidacyjnej
                val_running_corrects += torch.sum(preds == labels.data)  # Aktualizacja liczby poprawnych predykcji walidacyjnych

        val_epoch_loss = val_running_loss / len(dataloaders["val"].dataset)  # Obliczenie Å›redniej straty walidacyjnej
        val_epoch_acc = val_running_corrects.double() / len(dataloaders["val"].dataset)  # Obliczenie dokÅ‚adnoÅ›ci walidacyjnej

        print(f"Validation Loss: {val_epoch_loss:.4f}, Validation Acc: {val_epoch_acc:.4f}")  # Informacja o wynikach walidacji
        history["val_loss"].append(val_epoch_loss)  # Zapis straty walidacyjnej do historii
        history["val_acc"].append(val_epoch_acc.item())  # Zapis dokÅ‚adnoÅ›ci walidacyjnej do historii

        # Wczesne zatrzymywanie i zapisywanie punktu kontrolnego
        early_stopping(val_epoch_loss, model, checkpoint_path)  # Sprawdzenie warunku wczesnego zatrzymywania
        if early_stopping.early_stop:
            print("Early stopping")  # Informacja o wczesnym zatrzymaniu
            break

    # ZaÅ‚adowanie najlepszych wag modelu
    model.load_state_dict(torch.load(checkpoint_path))
    return model, history  # ZwrÃ³cenie wytrenowanego modelu i historii treningu

# Przypisanie DataLoaderÃ³w do zmiennej 'dataloaders'
dataloaders = {"train": train_loader, "val": val_loader}

```

W celu obserwacji historii treningu zostaÅ‚o dodane zapisywanie wynikÃ³w, a nastÄ™pnie ich wizualizacja za pomocÄ… wykresu.

![image](https://github.com/sit3kk/Bird_Detector/assets/69002597/a0383c80-bb6d-404b-8e26-74f63fd8662d)


## ğŸ“ˆ Przebieg Treningu
Od samego poczÄ…tku skutecznoÅ›Ä‡ trenowania rosÅ‚a (wykluczajÄ…c jeden spadek), jednoczeÅ›nie znacznie przyspieszyÅ‚ czas treningu (prawdopodobnie ze wzglÄ™du na uÅ¼ycie GPU). Ostatecznie udaÅ‚o siÄ™ uzyskaÄ‡ skutecznoÅ›Ä‡ na zbiorze testowym 99%, co byÅ‚o wynikiem powyÅ¼ej oczekiwaÅ„.

## ğŸ† Ostateczna Decyzja

Wykorzystanie architektury ResNet znaczÄ…co przebiÅ‚o rezultaty MobileNetV2 i zakoÅ„czyÅ‚o iteracjÄ™ w poszukiwaniu najlepszego rozwiÄ…zania

### Dlaczego tak siÄ™ staÅ‚o?

- BÅ‚Ä™dy metodologiczne w pierwszym modelu (niezbalansowane klasy, zÅ‚e dostosowanie modelu).
- GÅ‚Ä™bsza architektura ResNet dziÄ™ki zastosowaniu blokÃ³w resztkowych, ktÃ³re lepiej sprawdzajÄ… siÄ™ w uchwycaniu skomplikowanych wzorcÃ³w danych (np. porÃ³wnanie zdjÄ™cia ptaka i nietoperza).
- ResNet uÅ¼ywa wiÄ™kszej liczby parametrÃ³w, co pozwala na modelowanie bardziej zÅ‚oÅ¼onych funkcji.

Model miaÅ‚ za zadanie dziaÅ‚aÄ‡ po stronie serwera, wiÄ™c wiÄ™ksze uÅ¼ycie mocy obliczeniowej nie byÅ‚o aÅ¼ tak istotne jak w przypadku aplikacji mobilnych.

## ğŸ› ï¸ UÅ¼ycie Modeli

W pliku `models_predictions.ipynb` moÅ¼na zobaczyÄ‡ przykÅ‚ady uÅ¼ycia modeli na zdjÄ™ciach znalezionych w internecie oraz ich czasy dziaÅ‚ania, co potwierdza skutecznoÅ›Ä‡ ostatecznego rozwiÄ…zania.

W folderze `utils` mamy zdefiniowane pliki `mn_utils.py` oraz `rn_utils.py`, z ktÃ³rych moÅ¼emy importowaÄ‡ funkcje w celu predykcji zdjÄ™cia (ktÃ³re na wejÅ›ciu przyjmujÄ… Å›cieÅ¼kÄ™).

## ğŸ“¦ Instalacja

Aby uruchomiÄ‡ projekt, wykonaj poniÅ¼sze kroki:

1. Klonowanie repozytorium:
    ```bash
    git clone https://github.com/sit3kk/Bird_Detector
    ```

2. Aktywacja wirtualnego Å›rodowiska:
    ```bash
    python -m venv venv
    source ./venv/bin/activate
    ```

3. Instalacja wymaganych bibliotek:
    ```bash
    pip install -r requirements.txt
    ```
